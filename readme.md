# üöÄ Google Scraper Extravaganza (UI Version)

Welcome to the **Google Scraper Extravaganza**‚Äîa powerful, user-friendly Google scraping tool with a sleek graphical interface! Whether you're gathering research data or analyzing search results, this tool simplifies the process with a few clicks. Built with Tkinter for an easy-to-use UI, it‚Äôs perfect for users of all levels.

## üïµÔ∏è‚Äç‚ôÇÔ∏è What Does It Do?

This UI-based scraper allows you to specify search queries, select geolocations, and target specific domains (like `.com` or `.co.uk`) for scraping Google search results. The results are saved into **Excel (.xlsx)** files for easy access and data analysis.

## Features üéâ

- **Graphical Interface**: No coding required! Simple UI to configure your search and view progress.
- **Multiple Pages**: Fetch search results across multiple pages.
- **Geolocation Targeting**: Choose specific regions (e.g., US, UK) to scrape region-specific search results.
- **Domain Targeting**: Select which Google domain (e.g., `.com`, `.co.uk`) to use.
- **Excel Output**: Results are saved in **Excel (.xlsx)** format, neatly organized for further processing.

## üîß Getting Started

### 1. Clone or Download the Repository

Clone the repository or download it as a ZIP file:

```bash
git clone https://github.com/recycledrobot/google-scraper-ui.git
cd google-scraper-ui
```

OR [Download the ZIP](https://github.com/recycledrobot/Google-Scraper-Extravaganza/archive/refs/heads/main.zip)

### 2. Install Dependencies

Ensure you have Python installed, then run the following command to install the required dependencies:

```bash
pip install -r requirements.txt
```

### 3. Run the Scraper

Launch the UI with a simple command:

```bash
python scraper_ui.py
```

A graphical interface will pop up, allowing you to input search queries, select domains, choose geolocations, and configure the number of pages to scrape.

### 4. Configure Your Search in the UI

1. **Enter Your Search Query**: Type the keywords you want to search.
2. **Select Domains**: Choose from available Google domains (e.g., `.com`, `.co.uk`).
3. **Select Geolocations**: Pick the region(s) for targeted results.
4. **Set Number of Pages**: Choose how many result pages you want to scrape.

### 5. Start Scraping!

Once you‚Äôve filled in the fields, hit the **Scrape Data** button, and let the magic happen. Scraped data will be saved in the `results` folder as Excel files, organized by date, domain, and query.

### 6. Check Your Results

Your results will be neatly saved in Excel (.xlsx) format under the `results` folder, ready for your analysis.

---

Enjoy using the **Google Scraper Extravaganza (UI Version)**, and feel free to contribute or report issues!

